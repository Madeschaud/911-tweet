{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Basic Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set Style of Viz\n",
    "sns.set_style(\"darkgrid\")\n",
    "# sns.set_palette(palette='dark:#5A9_r')\n",
    "\n",
    "# Magic lines\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#sk\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>class_label</th>\n",
       "      <th>disaster_type</th>\n",
       "      <th>disaster_year</th>\n",
       "      <th>country</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>words_per_tweet</th>\n",
       "      <th>actionable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1107353602434183169</td>\n",
       "      <td>Maybe armchair critics like @lilomatic can app...</td>\n",
       "      <td>caution_and_advice</td>\n",
       "      <td>cyclone</td>\n",
       "      <td>2019</td>\n",
       "      <td>Madagascar, Mozambique, Malawi, Zimbabwe</td>\n",
       "      <td>maybe armchair critic like appreciate real sit...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1108735335733825536</td>\n",
       "      <td>RT @povozim: Total Zimbabwe on the fuel situat...</td>\n",
       "      <td>other_relevant_information</td>\n",
       "      <td>cyclone</td>\n",
       "      <td>2019</td>\n",
       "      <td>Madagascar, Mozambique, Malawi, Zimbabwe</td>\n",
       "      <td>total zimbabwe fuel situation country followin...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1107658470508191744</td>\n",
       "      <td>.@Emuia briefed Mr Cho Jaichel on the coordina...</td>\n",
       "      <td>sympathy_and_support</td>\n",
       "      <td>cyclone</td>\n",
       "      <td>2019</td>\n",
       "      <td>Madagascar, Mozambique, Malawi, Zimbabwe</td>\n",
       "      <td>briefed mr cho jaichel coordinated effort agen...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1113073066131800064</td>\n",
       "      <td>Disease outbreaks: INGC maps potential risk ar...</td>\n",
       "      <td>caution_and_advice</td>\n",
       "      <td>cyclone</td>\n",
       "      <td>2019</td>\n",
       "      <td>Madagascar, Mozambique, Malawi, Zimbabwe</td>\n",
       "      <td>disease outbreak ingc map potential risk area ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1108234590068637696</td>\n",
       "      <td>Goodmorning to you all a smile will brighten s...</td>\n",
       "      <td>sympathy_and_support</td>\n",
       "      <td>cyclone</td>\n",
       "      <td>2019</td>\n",
       "      <td>Madagascar, Mozambique, Malawi, Zimbabwe</td>\n",
       "      <td>goodmorning smile brighten someone day giving ...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             tweet_id  \\\n",
       "0           0  1107353602434183169   \n",
       "1           1  1108735335733825536   \n",
       "2           2  1107658470508191744   \n",
       "3           3  1113073066131800064   \n",
       "4           4  1108234590068637696   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  Maybe armchair critics like @lilomatic can app...   \n",
       "1  RT @povozim: Total Zimbabwe on the fuel situat...   \n",
       "2  .@Emuia briefed Mr Cho Jaichel on the coordina...   \n",
       "3  Disease outbreaks: INGC maps potential risk ar...   \n",
       "4  Goodmorning to you all a smile will brighten s...   \n",
       "\n",
       "                  class_label disaster_type disaster_year  \\\n",
       "0          caution_and_advice       cyclone          2019   \n",
       "1  other_relevant_information       cyclone          2019   \n",
       "2        sympathy_and_support       cyclone          2019   \n",
       "3          caution_and_advice       cyclone          2019   \n",
       "4        sympathy_and_support       cyclone          2019   \n",
       "\n",
       "                                    country  \\\n",
       "0  Madagascar, Mozambique, Malawi, Zimbabwe   \n",
       "1  Madagascar, Mozambique, Malawi, Zimbabwe   \n",
       "2  Madagascar, Mozambique, Malawi, Zimbabwe   \n",
       "3  Madagascar, Mozambique, Malawi, Zimbabwe   \n",
       "4  Madagascar, Mozambique, Malawi, Zimbabwe   \n",
       "\n",
       "                                         tweet_clean  words_per_tweet  \\\n",
       "0  maybe armchair critic like appreciate real sit...               25   \n",
       "1  total zimbabwe fuel situation country followin...                9   \n",
       "2  briefed mr cho jaichel coordinated effort agen...               20   \n",
       "3  disease outbreak ingc map potential risk area ...                9   \n",
       "4  goodmorning smile brighten someone day giving ...               19   \n",
       "\n",
       "   actionable  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "data =pd.read_csv('/Users/mathildedeschaud/code/Madeschaud/911-tweet/Data/clean_data.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set params\n",
    "max_features =10000\n",
    "max_len=300\n",
    "embedding_dim=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify X,y\n",
    "X = data['tweet_clean']\n",
    "y = data.actionable\n",
    "\n",
    "#split data\n",
    "X_train, X_test,y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 73693 different words in your corpus\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "tk =Tokenizer()\n",
    "tk.fit_on_texts(X_train)\n",
    "vocab_size = len(tk.word_index)\n",
    "print(f'There are {vocab_size} different words in your corpus')\n",
    "X_train_token = tk.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the inputs\n",
    "X_pad = pad_sequences(X_train_token, dtype='float32', padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 6.3000e+01, 1.7400e+02,\n",
       "        6.0000e+00],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 2.4000e+01, 8.0000e+00,\n",
       "        2.0563e+04],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 1.0500e+02, 5.6000e+01,\n",
       "        9.1000e+01],\n",
       "       ...,\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 1.9320e+03, 4.0300e+02,\n",
       "        7.3692e+04],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 3.1000e+03, 1.5200e+02,\n",
       "        8.2300e+02],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, ..., 3.2000e+01, 7.8000e+02,\n",
       "        6.0600e+02]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = Sequential()\n",
    "#embedding\n",
    "model.add(Embedding(input_dim=vocab_size+1,output_dim=2, mask_zero=True))\n",
    "\n",
    "#lstm\n",
    "model.add(LSTM(units=64, return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#compile\n",
    "model.compile(loss='binary_crossentropy', optimizer= 'rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_pad, y_train, batch_size=128, epochs=5, validation_split=0.2)\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss:.4f}')\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 500, 2)            81134     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 500, 64)           17152     \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 500, 32)           12416     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113855 (444.75 KB)\n",
      "Trainable params: 113855 (444.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "911-tweet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
