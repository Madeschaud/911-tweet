{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Basic Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from colorama import Fore\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "df_norm = pd.read_csv('/Users/mathildedeschaud/code/Madeschaud/911-tweet/tweet_911/Data/clean_nodis_124.csv')\n",
    "df_dis = pd.read_csv('/Users/mathildedeschaud/code/Madeschaud/911-tweet/tweet_911/Data/clean_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm['disaster_or_not']= 0\n",
    "df_dis['disaster_or_not']= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_norm, df_dis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>disaster_or_not</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>words_per_tweet</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>class_label</th>\n",
       "      <th>disaster_year</th>\n",
       "      <th>country</th>\n",
       "      <th>disaster_type</th>\n",
       "      <th>actionable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1270274</td>\n",
       "      <td>2001168103</td>\n",
       "      <td>Now you can put your iPhone to work for you! F...</td>\n",
       "      <td>0</td>\n",
       "      <td>put iphone work find today httpisgdkozh</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1025173</td>\n",
       "      <td>1932831900</td>\n",
       "      <td>@3oh3PFR oh no he didnt! see you in Australia!</td>\n",
       "      <td>0</td>\n",
       "      <td>oh didnt see australia</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6824</td>\n",
       "      <td>1469584314</td>\n",
       "      <td>@electra126 Uh, blame global warming for that ?</td>\n",
       "      <td>0</td>\n",
       "      <td>uh blame global warming</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1543779</td>\n",
       "      <td>2183846794</td>\n",
       "      <td>Finished a song with Ben today</td>\n",
       "      <td>0</td>\n",
       "      <td>finished song ben today</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704294</td>\n",
       "      <td>2256987111</td>\n",
       "      <td>@couver87 how come that everytime I'm online y...</td>\n",
       "      <td>0</td>\n",
       "      <td>come everytime im online vice versa</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    tweet_id                                         tweet_text  \\\n",
       "0     1270274  2001168103  Now you can put your iPhone to work for you! F...   \n",
       "1     1025173  1932831900    @3oh3PFR oh no he didnt! see you in Australia!    \n",
       "2        6824  1469584314   @electra126 Uh, blame global warming for that ?    \n",
       "3     1543779  2183846794                    Finished a song with Ben today    \n",
       "4      704294  2256987111  @couver87 how come that everytime I'm online y...   \n",
       "\n",
       "   disaster_or_not                              tweet_clean  words_per_tweet  \\\n",
       "0                0  put iphone work find today httpisgdkozh                6   \n",
       "1                0                   oh didnt see australia                4   \n",
       "2                0                  uh blame global warming                4   \n",
       "3                0                  finished song ben today                4   \n",
       "4                0      come everytime im online vice versa                6   \n",
       "\n",
       "   Unnamed: 0.1 class_label disaster_year country disaster_type  actionable  \n",
       "0           NaN         NaN           NaN     NaN           NaN         NaN  \n",
       "1           NaN         NaN           NaN     NaN           NaN         NaN  \n",
       "2           NaN         NaN           NaN     NaN           NaN         NaN  \n",
       "3           NaN         NaN           NaN     NaN           NaN         NaN  \n",
       "4           NaN         NaN           NaN     NaN           NaN         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disaster_or_not\n",
       "1    124096\n",
       "0    124000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.disaster_or_not.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124096, 12),\n",
       " Index(['Unnamed: 0', 'tweet_id', 'tweet_text', 'disaster_or_not',\n",
       "        'tweet_clean', 'words_per_tweet', 'Unnamed: 0.1', 'class_label',\n",
       "        'disaster_year', 'country', 'disaster_type', 'actionable'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dis.shape, df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0', 'tweet_id', 'Unnamed: 0.1', 'class_label',\n",
    "        'disaster_year', 'country', 'disaster_type', 'actionable'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>disaster_or_not</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>words_per_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Now you can put your iPhone to work for you! F...</td>\n",
       "      <td>0</td>\n",
       "      <td>put iphone work find today httpisgdkozh</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@3oh3PFR oh no he didnt! see you in Australia!</td>\n",
       "      <td>0</td>\n",
       "      <td>oh didnt see australia</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@electra126 Uh, blame global warming for that ?</td>\n",
       "      <td>0</td>\n",
       "      <td>uh blame global warming</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finished a song with Ben today</td>\n",
       "      <td>0</td>\n",
       "      <td>finished song ben today</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@couver87 how come that everytime I'm online y...</td>\n",
       "      <td>0</td>\n",
       "      <td>come everytime im online vice versa</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  disaster_or_not  \\\n",
       "0  Now you can put your iPhone to work for you! F...                0   \n",
       "1    @3oh3PFR oh no he didnt! see you in Australia!                 0   \n",
       "2   @electra126 Uh, blame global warming for that ?                 0   \n",
       "3                    Finished a song with Ben today                 0   \n",
       "4  @couver87 how come that everytime I'm online y...                0   \n",
       "\n",
       "                               tweet_clean  words_per_tweet  \n",
       "0  put iphone work find today httpisgdkozh                6  \n",
       "1                   oh didnt see australia                4  \n",
       "2                  uh blame global warming                4  \n",
       "3                  finished song ben today                4  \n",
       "4      come everytime im online vice versa                6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disaster_or_not\n",
       "1    124096\n",
       "0    124000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.disaster_or_not.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('obj2_clean_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/mathildedeschaud/code/Madeschaud/911-tweet/tweet_911/Data/obj2_clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_data():\n",
    "    #identify X,y\n",
    "    X = data['tweet_clean']\n",
    "    y = data.actionable\n",
    "\n",
    "    #split data\n",
    "    return train_test_split( X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "\n",
    "def tokenize_data(X_train, X_test):\n",
    "    # tokenize\n",
    "    tk =Tokenizer()\n",
    "    tk.fit_on_texts(X_train)\n",
    "\n",
    "    vocab_size = len(tk.word_index)\n",
    "    print(f'There are {vocab_size} different words in your corpus')\n",
    "\n",
    "    return vocab_size, tk.texts_to_sequences(X_train), tk.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "def initialize_model(vocab_size, embedding_dim):\n",
    "    # build model\n",
    "    model = Sequential()\n",
    "    #embedding\n",
    "    model.add(Embedding(input_dim=vocab_size+1,output_dim=embedding_dim, mask_zero=True))\n",
    "\n",
    "    #lstm\n",
    "    model.add(Bidirectional(LSTM(64, activation='tanh', return_sequences=True)))\n",
    "    # model.add(Bidirectional(LSTM(64, activation='tanh')))\n",
    "    model.add(Bidirectional(LSTM(32)))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    #compile\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'Recall', 'Precision'])\n",
    "    return model\n",
    "\n",
    "def model_bidirectional_lstm():\n",
    "    # set params\n",
    "    max_features =10000\n",
    "    max_len=300\n",
    "    embedding_dim=2\n",
    "\n",
    "    X_train, X_test,y_train, y_test = split_data()\n",
    "    vocab_size, X_train_token, X_test_token = tokenize_data(X_train, X_test)\n",
    "\n",
    "    # Pad the inputs\n",
    "    X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post',maxlen=max_len)\n",
    "    X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post',maxlen=max_len)\n",
    "\n",
    "    model = initialize_model(vocab_size, embedding_dim)\n",
    "\n",
    "    #initialize\n",
    "    print(Fore.MAGENTA + 'Le Bidirectional LSTM est lancé' + Fore.MAGENTA)\n",
    "    es = EarlyStopping(patience=10, restore_best_weights=True, monitor='val_precision')\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    checkpoint_path = 'Data/checkpoint/model-{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "    check = ModelCheckpoint(checkpoint_path, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "    history = model.fit(X_train_pad,\n",
    "                    y_train, batch_size=32,\n",
    "                    epochs=1,\n",
    "                    shuffle=True,\n",
    "                    validation_split = 0.2, #IMPORTANT éviter le data leakage\n",
    "                    callbacks = [es, check],\n",
    "                    verbose = 1)\n",
    "    # # Evaluate the model\n",
    "    # loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
    "    # print(f'Test loss: {loss:.4f}')\n",
    "    # print(f'Test accuracy: {accuracy:.4f}')\n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_test_pad) # Make cross validated predictions of entire dataset\n",
    "    print(classification_report(y_test,(y_pred > 0.5).astype(int))) # Pass predictions and true values to Classification report\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "911-tweet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
